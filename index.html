<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description"
    content="multi-view consistent style transfer network architecture that enables consistent style transfer between multiple viewpoints.">
  <meta name="keywords" content="MVS, Style Transfer, VGG, Radiance fields, Neural Rendering">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>MVCAST: Multi-View Consistent Artistic Style Transfer</title>



  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.jpg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<body>

  <!--nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://personl_page">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://link1.com">
            Link1
          </a>
          <a class="navbar-item" href="https://link2.com">
            Link2
          </a>
          <a class="navbar-item" href="https://link3.com">
            Link3
          </a>
          <a class="navbar-item" href="https://link4.com">
            Link4
          </a>
        </div>
      </div>
    </div>

  </div>
</nav-->


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">MVCAST: Multi-View Consistent Artistic Style Transfer</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="#">Anonymous authors</a></span><br>
              <a href="#">Links will be available soon</a></span>
              <!--span class="author-block">
              <a href="https://webpage">Name Surname</a><sup>1</sup>,</span-->

            </div>

            <div class="is-size-5 publication-authors">
              <!--span class="author-block"><sup>1</sup>University of ..,</span-->
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <span class="link-block">
                  <!-- PDF Link. -->
                  <a href="#" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>
                <span class="link-block">
                  <!-- arXiv -->
                  <a href="#" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>
                <span class="link-block">
                  <!-- Video Link. -->
                  <a href="#" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-youtube"></i>
                    </span>
                    <span>Video</span>
                  </a>
                </span>
                <span class="link-block">
                  <!-- Code Link. -->
                  <a href="#" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
                <!-- Dataset Link. -->
                <span class="link-block">
                  <a href="#" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="far fa-images"></i>
                    </span>
                    <span>Custom Data</span>
                  </a>
              </div>

            </div>
          </div>
        </div>
      </div>
    </div>
  </section>


  <section class="section">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>

              We present a modular multi-view consistent style transfer network architecture <span
                class="mvcast">mvcast</span> that enables consistent style transfer between multiple viewpoints of the
              same scene.
              This network architecture supports both sparse and dense views, making it versatile enough to handle a
              wide range of multi-view image datasets.
              The approach consists of three modules that perform specific tasks related to style transfer, namely
              content preservation, image transformation, and multi-view consistency enforcement.
              We evaluate our approach extensively across multiple application domains including depth-map-based point
              cloud fusion, mesh reconstruction, and novel-view synthesis.
              The results demonstrate that the framework produces high-quality stylized images while maintaining
              consistency across multiple views, even for complex styles that involve mosaic tessellations or extensive
              brush strokes.
              Our modular multi-view consistent style transfer framework is extensible and can easily be integrated with
              various backbone architectures, making it a flexible solution for multi-view style transfer.
            </p>
          </div>
        </div>
      </div>

      <section class="hero teaser">
        <div class="container is-max-desktop">
          <div class="hero-body">
            <img src="./static/images/pipeline_highlighted.png" alt="Description of the image" style="width: 770px;">

          </div>
        </div>
      </section>
      <!--/ Abstract. -->

      <!-- Paper video. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Paper Video (will be available soon)</h2>
          <div class="publication-video">

            <iframe src="https://www.youtube.com/embed/#" frameborder="0" allow="autoplay; encrypted-media"
              allowfullscreen></iframe>
          </div>
        </div>
      </div>
      <!--/ Paper video. -->
    </div>
  </section>


  <section class="section">
    <div class="container is-max-desktop">



      <div class="columns is-centered">
        <div class="column is-full-width">
          <h1 class="title is-2">Results</h1>

          <h2 class="title is-3">Pointcloud reconstruction </h2>
          <div class="columns is-centered">
            <!-- Visual Effects. -->
            <div class="column">
              <div class="content">
                <h3 class="title is-4">Texturing quality</h3>
                <p>
                  The bird point cloud reconstructed using depth
                  map fusion from the 49 input images and a style image.
                  This experiment demonstrates the stylization capability of
                  our network (CasMVSNet_UNet) to reveal finer details in
                  textured areas, even in shadowed regions. <br>
                </p>
                <img src="./static/images/birds_coloring.png" alt="Description of the image">
              </div>
            </div>
            <!--/ Visual Effects. -->

            <!-- Matting. -->
            <div class="column">
              <h3 class="title is-4">Reconstruction quality</h3>
              <div class="columns is-centered">
                <div class="column content">
                  <p>
                    Comparison of the point clouds reconstructed (CasMVSNet_UNet)
                    from the original input images (left column) and stylized
                    images (right column). Top: colored with original inputs. Middle: colored with stylized colors.
                    Bottom: uniform coloring.
                  </p>
                  <img src="./static/images/birds_geometry.png" alt="Description of the image" style="width: 450px;">
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
      <h3 class="title is-4">Comparing stylization backbones</h3>
      <div class="columns is-centered">
        <div class="column content">
          <img src="./static/images/Scan122.png" alt="Description of the image">
          <p>
            Point cloud reconstruction results using PatchmatchNet backbone (Geometry + Coloring). The point clouds (a),
            (b), and (c)
            are identical in terms of geometry, with (a) colored by the 64 original input images, (b) colored by the
            stylized images
            using the output of Patchmatchnet UNet, and (c) colored by the stylized images using the output of
            Patchmatchnet AdaIN.
            (d) and (e) are reconstructed from only the stylized images.
          </p>
        </div>
      </div>
      <h2 class="title is-3">Neural rendering and mesh reconstruction experiments</h2>
      <div class="columns is-centered">
        <div class="column content">
          <img src="./static/images/mesh_styling.png" alt="Description of the image">
          <p>
            Neural mesh reconstruction results. First row: CasMVSNet UNet. Second row: CasMVSNet AdaIN. Third row:
            PatchmatchNet UNet. Fourth row: PatchmatchNet AdaIN. The columns in the figure are as follows: (a) Input image. (b)
            Stylized image, (c) The stylized mesh surface rendering learned by IDR. (d) The mesh reconstructed from the stylized
            images. (e) The mesh reconstruction from the original input images.
          </p>
        </div>
      </div>
      <h3 class="title is-4">Mesh editing</h3>
      <div class="columns is-centered">
        <div class="column content">
          <img src="./static/images/mesh_editing.png" alt="Description of the image">
          <p>
            Mesh editing effect. The reconstructed mesh demonstrates stripe-like geometric features.
          </p>
        </div>
      </div>
      <h3 class="title is-4">Mesh coloring</h3>
      <div class="columns is-centered">
        <div class="column content">
          <img src="./static/images/mesh_coloring.png" alt="Description of the image">
          <p>
            Mesh surface coloring (Geometry + Coloring). Meshes (a) and (b) have the same geometric properties but differ
            in their coloring. Specifically, (a) and (c) are colored using 64 original input images, while (b) and (d) are colored using the
            stylized images. The geometry of (a) and (b) is derived from the original inputs, while the geometry of (c) and (d) is learned
            from the stylized images.
          </p>
        </div>
      </div>
      <br>
      <br>
      <h3 class="title is-3">Novel view synthesis </h2>
        <h3 class="title is-4">NeRF results</h3>
        <div class="columns is-centered">
          <div class="column content">
            <img src="./static/images/nvs.png" alt="Description of the image">
            <p>
              Novel view synthesis with four different styles.
            </p>
          </div>
        </div>  
    </div>

      <section class="hero is-light is-small">
        <div class="hero-body">
          <div class="container">
            <div id="results-carousel" class="carousel results-carousel">
              <div class="item item-mansion_artiste">
                <video poster="" id="mansion_artiste" autoplay controls muted loop playsinline height="100%">
                  <source src="./static/videos/mansion_artiste.mp4" type="video/mp4">
                </video>
              </div>
              <div class="item item-family">
                <video poster="" id="family" autoplay controls muted loop playsinline height="100%">
                  <source src="./static/videos/family.mp4" type="video/mp4">
                </video>
              </div>
              <div class="item item-truck_v2">
                <video poster="" id="truck_v2" autoplay controls muted loop playsinline height="100%">
                  <source src="./static/videos/truck_v2.mp4" type="video/mp4">
                </video>
              </div>
              <div class="item item-sculp_lady">
                <video poster="" id="sculp_lady" autoplay controls muted loop playsinline height="100%">
                  <source src="./static/videos/lady_sculp.mp4" type="video/mp4">
                </video>
              </div>
              <div class="item item-playground">
                <video poster="" id="playground" autoplay controls muted loop playsinline height="100%">
                  <source src="./static/videos/playground.mp4" type="video/mp4">
                </video>
              </div>
            </div>
          </div>
        </div>
      </section>
      <div class="container is-max-desktop">
        <h3 class="title is-4">Comparison </h3>
        <p>
          We demonstrate the strength of our technique by estimating poses and acquiring radiance fields directly from stylized images. 
          What sets our approach apart from others is its ability to stylize images that can be utilized directly for radiance field computation. 
          To ensure a fair comparison, our novel views were generated from a viewpoint chosen as the default camera trajectory by the ARF author. 
          To eliminate view dependency and promote color consistency, ARF depending on underlying NeRF method
          either constrains all spherical harmonics components except the first, or zeroes the view directions when passing them to the rendering MLP. 
          In contrast, our method is capable of generating durable radiance fields without any limitations.       
        </p>
        <div class="columns is-centered">
          <div class="column content">
            <img src="./static/images/nvs_comparison.jpg" alt="Description of the image">
            <p>
              Novel-view synthesis comparison with ARF on two scenes.
              For each scene, the top row shows the result of ARF, and the bottom row shows the radiance fields directly computed from our stylized images.
           </p>
          </div>
        </div>
        <div class="columns is-centered">
          <div class="column content">
              <h2 class="title is-3">ARF</h2>
              <p>
                ARF lorem ipsum dolor sit amet, consectetur adipiscing elit. Integer posuere erat a ante.
              </p>
              <video id="ARF_playground" autoplay controls muted loop playsinline height="400px">
                <source src="./static/videos/ARF_playground.mov" type="video/mp4">
              </video>
              <br>
              <video id="ARF_family" autoplay controls muted loop playsinline height="400px">
                <source src="./static/videos/ARF_family.mov" type="video/mp4">
              </video>
            </div>
          
            <div class="column content">
              <h2 class="title is-3">Ours</h2>
              <p>
                Our lorem ipsum dolor sit amet, consectetur adipiscing elit. Integer posuere erat a ante.
              </p>
                <video id="OUR_playground" autoplay controls muted loop playsinline height="400px">
                  <source src="./static/videos/our_playground.mov" type="video/mp4">
                </video>
                <video id="OUR_family" autoplay controls muted loop playsinline height="400px">
                  <source src="./static/videos/our_family.mov" type="video/mp4">
                </video>
          </div>
        </div>
        <script>
          document.getElementById('OUR_family').playbackRate = 0.59; // Slows down the OUR video by half
          document.getElementById('OUR_playground').playbackRate = 0.59; // Slows down the OUR video by half
        </script>
      <div class="columns is-centered">
        <div class="column is-full-width">
          <h2 class="title is-3">Related Links</h2>

          <div class="content has-text-justified">
            <p>
              ARF, NeRF, Instant-NGP, IDR, Nerfstudio
            </p>
            <p>
              CasMVSNet, PatchMatchNet
            </p>
            <p>
              AdaIN, Style Transfer, Fast Style Transfer
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>


  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@article{...2023mvcast,
  author    = {...},
  title     = {MVCAST: Multi-View Consistent Artistic Style Transfer},
  journal   = {ICCV},
  year      = {2023},
}</code></pre>
    </div>
  </section>


  <footer class="footer">
    <div class="container">
      <div class="content has-text-centered">
        <a class="icon-link" href="#">
          <i class="fas fa-file-pdf"></i>
        </a>
        <a class="icon-link" href="https://github.com/" class="external-link" disabled>
          <i class="fab fa-github"></i>
        </a>
      </div>
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This website is licensed under a <a rel="license"
                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
                Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>
            <p>
              We adapted <a href="https://github.com/nerfies/nerfies.github.io">source
                code of Nerfies paper</a>  to create this website.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

</body>

</html>